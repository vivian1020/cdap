---
# Please keep this file alphabetically sorted!
commons:
  cask: CASK
  cdap: CDAP
  entity:
    application:
      plural: Applications
      short-singular: App
      short-plural: Apps
      singular: Application
    artifact:
      plural: Artifacts
      singular: Artifact
    cdap-data-pipeline:
      plural: Data Pipelines
      singular: Data Pipeline
    cdap-data-streams:
      plural: Data Streams
      singular: Data Stream
    dataset:
      plural: Datasets
      singular: Dataset
    datasetinstance:
      plural: Datasets
      singular: Dataset
    flow:
      plural: Flows
      singular: Flow
    mapreduce:
      plural: Mapreduce
      singular: Mapreduce
    program:
      plural: Programs
      singular: Program
    service:
      plural: Services
      singular: Service
    spark:
      plural: Spark
      singular: Spark
    stream:
      plural: Streams
      singular: Stream
    worker:
      plural: Workers
      singular: Worker
    workflow:
      plural: Workflows
      singular: Workflow
    view:
      plural: Stream Views
      singular: Stream View
  hydrator: Cask Hydrator
  market: Cask Market
  resource-center: Resource Center
  tracker: Cask Tracker
  nameLabel: Name
  descriptionLabel: Description
  formatLabel: Format
  schemaLabel: Schema
features:
  Home:
    Title: CDAP - Home
    emptyMessage: No entities found in the system.
    Cards:
      type: "Type: "
    Header:
      filters: Filters
      search-placeholder: Search entities ...
      sort: Sort
      sortOptions:
        nameAsc: A - Z
        nameDesc: Z - A
    FastActions:
      deleteConfirmation: Are you sure you want to delete {entityId}?
      truncateConfirmation: Are you sure you want to truncate {entityId}?
  Dashboard:
    Title: Dashboard
  Management:
    Title: Administrator
    Top:
      version-label: Version
      time-label: Uptime
      services: Services
      updated: Last updated
      updated-label:
        plural: seconds ago
        singular: second ago
    Panels:
      nodes: Nodes
      virtual-cores: Virtual Cores
      memory: Memory
      application: Application
    Configure:
      title: Configure
      buttons:
        add-ns: Add Namespace
        view-config: View Configurations
        manage-ns: Manage Namespaces
        delete-ns: Delete Namespace
        manage-roles: Manage Roles
        reset-instance: Reset Instance
        tag-management: Tag Management
        instance-preference: Instance Preference
        delete-datasets: Delete All Datasets
        view-invalid: View Invalid Transactions
    Component-Overview:
      label: Component Overview
      cards:
        cdh: CDH
        yarn: YARN
        hdfs: HDFS
        zookeeper: Zookeeper
        kafka: Kafka
        spark: Spark

  Market:
    search-placeholder: Search
    connectErrorMessage: Cannot connect to Market
    tabs:
      all: All
      applications: Applications
      artifacts: Artifacts
      dashboards: Dashboards
      datapacks: Datapacks
      datasets: Datasets
      examples: Examples
      pipelines: Pipelines
      plugins: Plugins
      useCases: Use Cases
    action-types:
      create_stream:
        name: Create
      create_app:
        name: Create
      create_pipeline_draft:
        name: Create
      create_pipeline:
        name: Create
      create_artifact:
        name: Create
      informational:
        name: Download
      load_datapack:
        name: Load
  MarketEntityModal:
    version: "Version :"
  Navbar:
    CDAP:
      dashboard: Dashboard
      home: Home
      management: Management
    HeaderActions:
      caskHome: Cask Home
      documentation: Documentation
      logout: Logout
      signedInAs: Signed in as
      support: Support
    Sidebar:
      extension: "Extensions:"

  Resource-Center:
    Stream:
      label: Stream
      description: Stream is used to ingest data into HDFS in real-time or batch.
      actionbtn0: Create
    Application:
      label: Application
      description: Upload a custom Application artifact or create an instance of Application from existing Artifact.
      actionbtn0: Upload
      actionbtn-1: Create
    Stream-View:
      label: Stream View
      description: Stream View is non-materialized view over a Stream with schema on read capability. Create a view over existing Stream.
      actionbtn0: Create
    HydratorPipeline:
      label: Hydrator Pipeline
      description: Hydrator pipeline allows you to ingest, egress and process data to, from and within Hadoop.
      actionbtn0: Create
    Artifact:
      label: Artifact
      description: Artifact is a JAR file that contains either a native Application or collection of Plugins.
      actionbtn0: Upload
    Plugins:
      label: Plugins
      description: Plugin is a easy way to extend the functionality of a Application.
      actionbtn0: Upload

  SplashScreen:
    buttons:
      getStarted: Read the Docs
      introduction: Intro to CDAP
      register: Register for Updates
    intro-message: Unified Integration Platform for Big Data
    title: Welcome to Cask Data Application Platform
    version-label: Version 4.0.0 Preview
  Wizard:
    ArtifactUpload:
      Step1:
        description: Upload your artifact JAR
        shorttitle: Upload Artifact
        title: Upload JAR
        uploadHelperText: Upload the third party artifact that was downloaded from the previous step
        filePathLabel: Choose file
      Step2:
        description: Configure the settings for your artifact
        shorttitle: Artifact Configuration
        title: Configure Artifact
        parentArtifactLabel: Parent Artifact
        nameLabel: Name
        typeLabel: Type
        classnameLabel: Class Name
        descriptionLabel: Description
      headerlabel: Upload Artifact
    Done: Done
    Informational:
      Step1:
        description: Please follow the steps specified below to configure Hydrator plugin to read from your database
        shorttitle: Third Party Artifact Information
        title: Information
      headerlabel: Third Party Artifact
    Skip: Skipped
    FailedMessage: Failed to {step}
    StreamCreate:
      Step1:
        shorttitle: General Information
        title: General
        description: Provide information about Stream you want to create.
        ttllabel: Event Life Time
        ttl-placeholder: Specify time to live events in seconds
      Step2:
        shorttitle: Setup Format and Schema
        title: Set Format and Schema
        description: Setting format and schema allows you to perform schema-on-read.
      Step3:
        shorttitle: Trigger Setup
        title: Setup Trigger
        description: Setting up Trigger configures system to notify systems observing to start processing.
        thresholdlabel: The stream will notify any observers upon reaching this threshold to start processing of the data in this Stream
        mblabel: Megabytes (MB)
      Step4:
        shorttitle: Upload Data
        title: Upload Data
        description: Upload Data to the Stream you created
      headerlabel: Create Stream
    UploadData:
      Step1:
        shorttitle: View Data
        title: View Data
        description: Shows the data for your reference that would be uploaded to a destination
      Step2:
        shorttitle: Select Destination
        title: Select Destination
        description: Select the destination where the data needs to be uploaded
        dataentitynameplaceholder: Dataset/Stream Name
        destinationtype: Destination Type
        destinationname: Destination Name
      headerlabel: Upload Data
    PublishPipeline:
      Step1:
        shorttitle: Configure pipeline
        title: Configure pipeline
        description: Specify the name of the pipeline
      pipelinenameplaceholder: Pipeline name
      headerlabel: Publish Pipeline
    HydratorPipeline:
      title: Create Data Pipeline
      message: Choose the pipeline type you would like to create
      batchLinkLabel: Batch Pipeline
      realtimeLinkLabel: Realtime Pipeline

    Add-Namespace:
       Step1:
         ssd-label: "General Information"
         sld-desc:  "Specifies the name and the description of Namespace"
         name-label: "Name"
         name-placeholder: "Name of the namespace you would like to have"
         description-label: "Description"
         description-placeholder: "Description"
         scheduler-queue-label: "Scheduler Queue"
         scheduler-queue-placeholder: "Specify the YARN queue name to be associated with this namespace"
       Step2:
         ssd-label: "Namespace Mapping"
         sld-label: "Specifies mapping of namespace resources to the underlying existing storage resources"
         hdfs-root-directory-label: "HDFS Root Directory"
         hdfs-root-directory-placeholder: "Specify the root directory of HDFS to be used as this namespace root"
         hive-db-name-label: "Hive Database Name"
         hive-db-name-placeholder: "Specify the Hive database name to be used for this namespace"
         hbase-nm-name-label: "HBase Namespace Name"
         hbase-nm-name-placeholder: "Specify the name of the existing namespace in HBase to be used for this namespace"
       Step3:
         ssd-label: "Security"
         sld-label: "Specifies credentials for securely impersonating programs running as specified user"
         principal-label: "Principal"
         principal-placeholder: "Specifies the user to be impersonated for all jobs running in this namespace"
         keytab-uri-label: "Keytab URI"
         keytab-uri-placeholder: "Specifies the location to keytab file associated with the principal"
       Step4:
         ssd-label: "Preferences"
         sld-label: "Specify preferences to applied at the namespace level"
         name-label: "Name"
         name-placeholder: "Preference name"
         value-label: "Value"
         value-placeholder: "Preference value"
       Status:
         creation-error-desc: "Failed to create namespace '%s'"
         creation-success-desc: "Successfully created namespace '%s'"

...
